##### cluster parameter #####

# Available CLUSTER includes: zebra_dg_ai_cluster0, zebra_hz_ai_cluster0, zebra_jd_kaola_cluster0
export CLUSTER=zebra_dg_ai_cluster0

# Available FRAMEWORK_NAME: https://dl-file-server.hz.netease.com/conda_repo/
#export FRAMEWORK_NAME=tensorflow:tf-1.13.1-cuda9-hvd-0.16.4-tb-1.13.0
export FRAMEWORK_NAME=pytorch:torch-0.4.1-mxnet-1.5.0-hvd-0.16.4-dev
#export FRAMEWORK_NAME=tensorflow:tf-1.13.1-cuda9-hvd-dev-tb-1.13.0
# export FRAMEWORK_NAME=tensorflow:tf-1.13.1-cuda9-hvd-0.15.2-tb-1.13.0

# JOB_DIR_BASE is used to specify the workspace of the slurm jobs.
# It should be user's home directory.
export JOB_DIR_BASE=/home/huting3
# Request a specific partition for the resource allocation.
# Use sinfo command to see which partitions can be used.
export PARTITION=gpu_audio,gpu_image
#export PARTITION=gpu_8_1080ti,gpu_1_k40m
# Name of the job.
export JOB_NAME=huting3_hvd_join_test
# Set a time limit on the job allocation.
# Acceptable time formats include:
# "minutes", "minutes:seconds", 
# "hours:minutes:seconds", "days-hours", 
# "days-hours:minutes" and "days-hours:minutes:seconds".
export TIME=10:00
# Specify a minimum of minnodes nodes be allocated to this job.
export NODES=2
# Specify a comma delimited list of generic consumable resources. 
# The format of each entry on the list is "name[[:type]:count]". 
# The name is that of the consumable resource. 
# The count is the number of those resources. 
# The specified resources will be allocated to the job on each node.
export GRES=gpu:1
# Specify a maximum of number tasks to be launched.
export NTASKS=2
# Specify the number of task to be launched on each node.
export TASKS_PER_NODE=1
# Specify the number of cpus requested per task.
export CPUS_PER_TASK=10
